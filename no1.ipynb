{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7f2702aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12s</td>\n",
       "      <td>(dahui )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here are two islands.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(다희)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18s</td>\n",
       "      <td>(dahui )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On these islands, you focus only on each other...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(다희)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22s</td>\n",
       "      <td>(dahui )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>under limited conditions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(다희) 그러면 한 분은 0표를 받았다는 거죠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>01:00:23</td>\n",
       "      <td>(gyuhyeon ) geuleohjyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(규현) 그렇죠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>01:00:59</td>\n",
       "      <td>jamag : baehaneul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>자막: 배하늘</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time                   Subtitle Speaker  \\\n",
       "0          12s                   (dahui )     NaN   \n",
       "1          NaN                       (다희)     NaN   \n",
       "2          18s                   (dahui )     NaN   \n",
       "3          NaN                       (다희)     NaN   \n",
       "4          22s                   (dahui )     NaN   \n",
       "...        ...                        ...     ...   \n",
       "2011       NaN  (다희) 그러면 한 분은 0표를 받았다는 거죠     NaN   \n",
       "2012  01:00:23     (gyuhyeon ) geuleohjyo     NaN   \n",
       "2013       NaN                   (규현) 그렇죠     NaN   \n",
       "2014  01:00:59          jamag : baehaneul     NaN   \n",
       "2015       NaN                    자막: 배하늘     NaN   \n",
       "\n",
       "                                            Translation Interactions  \n",
       "0                                 Here are two islands.          NaN  \n",
       "1                                                   NaN          NaN  \n",
       "2     On these islands, you focus only on each other...          NaN  \n",
       "3                                                   NaN          NaN  \n",
       "4                              under limited conditions          NaN  \n",
       "...                                                 ...          ...  \n",
       "2011                                                NaN          NaN  \n",
       "2012                                               Yes.          NaN  \n",
       "2013                                                NaN          NaN  \n",
       "2014                                                NaN          NaN  \n",
       "2015                                                NaN          NaN  \n",
       "\n",
       "[2016 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "\n",
    "import pandas as pd\n",
    "path = ('singlesinfernos1e1.xlsx')\n",
    "xl = pd.ExcelFile(path)\n",
    "df1 = xl.parse('e1')\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd7d63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear all rows that have NaN as either speaker or interactions\n",
    "df1.dropna(subset=['Speaker', 'Interactions'], how='all',inplace=True)\n",
    "df1.drop('Subtitle', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c6d7e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yue\n",
      "[nltk_data]     Ning\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yue\n",
      "[nltk_data]     Ning\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords using nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df1['Translation'] = df1['Translation'].apply(lambda x: ' '.join([word for word in x.replace('-','').replace('?','').replace('.','').replace(',','').split() if word not in (stop)]))\n",
    "df1['Translation'] = df1['Translation'].astype(str).str.lower()\n",
    "df1['Translation'] = df1['Translation'].apply(lambda x: ' '.join([item for item in x.split() if len(item)>3]))\n",
    "\n",
    "# lemmatize - words into root form\n",
    "nltk.download('wordnet')\n",
    "wordnet_lem = WordNetLemmatizer()\n",
    "df1['Translation'] = df1['Translation'].apply(wordnet_lem.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e61ca6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalities & sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ce5f5bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b452f26193944a483c1a02fe8d0d8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='person', options=('Hyeonjung', 'Se-hoon', 'Jun-sik', 'Si-hun', 'Ji…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# need to make interactive functionality to choose the person you want\n",
    "\n",
    "\n",
    "x,y = np.ogrid[:300, :300]\n",
    "mask = (x-150) ** 2 + (y-150) ** 2 > 130 ** 2\n",
    "mask = 255 * mask.astype(int)\n",
    "\n",
    "copy = df1\n",
    "cast = ['Hyeonjung','Se-hoon','Jun-sik','Si-hun','Jin-taek', 'Ji-yeon','So-yeon','Yea-won','Ji-a']\n",
    "c = Dropdown(options=cast)\n",
    "\n",
    "@interact\n",
    "def choose_person(person=c):\n",
    "    df2 = copy['Translation'].where(copy['Speaker'] == person)\n",
    "    df2.dropna(inplace=True)\n",
    "    all_words_person = ''.join([word for word in df2])\n",
    "\n",
    "    wordcloud = WordCloud(background_color=\"white\", repeat=True, mask=mask).generate(all_words_person)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "# bar graph to show the sentiments of each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b386be04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Time  Speaker                   Translation  \\\n",
      "892   1900-01-01 05:43:00      NaN             seem approachable   \n",
      "894   1900-01-01 05:46:00      NaN         looks different smile   \n",
      "898   1900-01-01 05:50:00      NaN  when there's expression face   \n",
      "900   1900-01-01 05:53:00      NaN         idea thinking feeling   \n",
      "906   1900-01-01 06:06:00  se-hoon               smile beautiful   \n",
      "...                   ...      ...                           ...   \n",
      "1530  1900-01-01 22:17:00      NaN                     glad like   \n",
      "1532  1900-01-01 22:19:00      NaN              it's really good   \n",
      "1534  1900-01-01 22:20:00      NaN        like it's really tasty   \n",
      "1598  1900-01-02 00:37:00      NaN           i'll talk know like   \n",
      "1600  1900-01-02 00:40:00      NaN             barely talk today   \n",
      "\n",
      "          Interactions PersonOne PersonTwo  \n",
      "892      Se-hoon, Ji-a   Se-hoon      Ji-a  \n",
      "894      Jun-sik, Ji-a   Jun-sik      Ji-a  \n",
      "898      Se-hoon, Ji-a   Se-hoon      Ji-a  \n",
      "900      Se-hoon, Ji-a   Se-hoon      Ji-a  \n",
      "906   Se-hoon, Ji-yeon   Se-hoon   Ji-yeon  \n",
      "...                ...       ...       ...  \n",
      "1530  Se-hoon, Se-yeon   Se-hoon   Se-yeon  \n",
      "1532  Se-hoon, Se-yeon   Se-hoon   Se-yeon  \n",
      "1534  Se-hoon, Se-yeon   Se-hoon   Se-yeon  \n",
      "1598     Se-hoon, Ji-a   Se-hoon      Ji-a  \n",
      "1600     Se-hoon, Ji-a   Se-hoon      Ji-a  \n",
      "\n",
      "[61 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Looking at interactions - match two people; how do they feel about each other? \n",
    "# And which two people have the most positive/ negative feelings\n",
    "\n",
    "df3 = df1.copy(deep=True)\n",
    "df3[['PersonOne', 'PersonTwo']] = df1['Interactions'].str.split(', ', expand=True)\n",
    "df3.dropna(subset=['Interactions'], how='all',inplace=True)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a0054030",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Jun-sik', 'Yea-won'): 1.5177, ('Jin-taek', 'Yea-won'): 0.0, ('Jun-sik', 'Ji-a'): 0.3612, ('Jin-taek', 'Ji-a'): 0.0, ('Se-hoon', 'Ji-yeon'): 4.911700000000001, ('Hyeonjung', 'Ji-yeon'): 0.0, ('Jun-sik', 'So-yeon'): 1.4448, ('Jin-taek', 'So-yeon'): 0.7269, ('Se-hoon', 'Yea-won'): 0.0, ('Si-hun', 'Ji-yeon'): 0.0, ('Hyeonjung', 'Yea-won'): 0.0, ('Se-hoon', 'Ji-a'): 0.4892, ('Si-hun', 'Yea-won'): 0.0, ('Hyeonjung', 'Ji-a'): 3.9137, ('Si-hun', 'Ji-a'): 0.0, ('Se-hoon', 'So-yeon'): 0.0, ('Hyeonjung', 'So-yeon'): 0.0, ('Si-hun', 'So-yeon'): 0.0, ('Jun-sik', 'Ji-yeon'): 0.0, ('Jin-taek', 'Ji-yeon'): 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Yue\n",
      "[nltk_data]     Ning\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, Dropdown\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "maleList = ['Hyeonjung','Se-hoon','Jun-sik','Si-hun','Jin-taek']\n",
    "femaleList = ['Ji-yeon','So-yeon','Yea-won','Ji-a']\n",
    "\n",
    "df4 = df3.copy(deep=True)\n",
    "\n",
    "df5 = df4\n",
    "df5.dropna(subset=['Translation'])\n",
    "\n",
    "def calculate_polarity(df5):\n",
    "\n",
    "    # change data structure\n",
    "    df5['Polarity'] = df4['Translation'].apply(lambda x: analyser.polarity_scores(x))\n",
    "    df5 = pd.concat([df5.drop(['Polarity'], axis=1), df5['Polarity'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # create sentiment\n",
    "    df5['Sentiment'] = df5['compound'].apply(lambda x: 'Positive' if x > 0 else 'Neutral' if x==0 else 'Negative')\n",
    "    return df5\n",
    "\n",
    "df5 = calculate_polarity(df5)\n",
    "\n",
    "# calculate sentiment for every pair\n",
    "pairs = set()\n",
    "for m in maleList:\n",
    "    for f in femaleList:\n",
    "        pairs.add((m,f))\n",
    "\n",
    "sentiment = {}\n",
    "for p1,p2 in pairs:\n",
    "    temp_df = df5.loc[(df5['PersonOne'] == p1)]\n",
    "    temp_df = temp_df.loc[(temp_df['PersonTwo'] == p2)]\n",
    "    sentiment[(p1,p2)] = temp_df['compound'].sum()\n",
    "\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a768f599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3b05e1d1a6464da2409136edde4a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='male', options=('Hyeonjung', 'Se-hoon', 'Jun-sik', 'Si-hun', 'Jin-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "m = Dropdown(options=maleList)\n",
    "f = Dropdown(options=femaleList)\n",
    "@interact(male=m)\n",
    "def generate_graph(male):\n",
    "    y_axis = []\n",
    "    for f in femaleList:\n",
    "        y_axis.append(sentiment[(male,f)])\n",
    "    plt.bar(femaleList,y_axis)\n",
    "    plt.title('Sentiment Male and Female')\n",
    "    plt.xlabel('Gals')\n",
    "    plt.ylabel('Sentiment')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
